---
title: Install Cloud Pak for Data 3.0.1 on IBM Managed Openshift 4.3 (ROKS)
---

import Globals from 'gatsby-theme-carbon/src/templates/Globals';

<PageDescription>

</PageDescription>

## Install Cloud Pak for Data 3.0.1 on IBM Managed Openshift 4.3 (ROKS)

### Sizing Openshift Cluster for Cloud Pak for Data 3.0.1

Sizing Worker Nodes based on Services that are to be installed. Refer : https://salesconfig.ibmcloudpack.com/sales/#/zen/configure
To do the sizing

Please note that if you want to install Watson AI services (Watson Assistant, Watson Discovery, Watson AIOps, Watson Language Translator, Watson Speech to Text, Watson Text to Speech) size them separately as they will need bare metal worker nodes and will not work on virtual server worker nodes.

### Provision Openshift 4.3 Cluster on IBM Cloud

**Note:** Make sure you have Administrator and Manager lever permission on the account where you are provisioning the cluster.

Provision Openshift 4.3 Cluster from IBM Cloud console. Select Virtual Server Worker nodes based on the above sizing calculations. If you are installing Watson AI services, we will add Bare metal worker nodes post the cluster creation.

Once the cluster is created, create a new worker pool which will have bare metal servers required for Watson AI Services installation.



Once the cluster is ready, launch its console and on the right top corner, from copy login command, get the token to login to Openshift cluster remotely using cli
 

Make sure you have a system with Openshift and IBM Cloud cli installed.
https://cloud.ibm.com/docs/openshift?topic=openshift-openshift-cli#cli_oc
https://cloud.ibm.com/docs/cli/reference/bluemix_cli/download_cli.html

Execute oc login command obtained in above step from Openshift Web Console

### Setting up Openshift Cluster for Cloud Pak for Data Installation

1.	Create an external route of Openshift Image registry.
Use token obtained in abive step to login from a system to OpenShift Cluster and run below commands to create an external route

```
oc create route reencrypt --service=image-registry -n openshift-image-registry
oc annotate route image-registry --overwrite haproxy.router.openshift.io/balance=source -n openshift-image-registry
```

2.	Resize image registry storage volume
Default size of Openshift image registry will not be sufficient to load images if you are going to install multiple Services on Cloud Pak for Data. Hence it needs to be resized to 200GB. Run below commands to do it.

ibmcloud login (login into Account where your Openshift Cluster is setup)
```
registry_pv=`oc get pvc -n openshift-image-registry | grep "image-registry-storage" | awk '{print $3}'`
volid=`oc describe pv $registry_pv -n openshift-image-registry | grep volumeId`
IFS='='
read -ra vol <<< "$volid"
volume=${vol[1]}
echo volume id is $volume
ibmcloud sl file volume-modify $volume --new-size 200 --new-tier 10 –force
```

3.	Set kernel parameters (https://www.ibm.com/support/knowledgecenter/SSQNUZ_3.0.1/cpd/install/node-settings.html)
Since we do not have ssh access to worker nodes on ROKS, we will use daemonset to perform kernel parameter settings. Create setkernelparameters.yaml file with below contents

```apiVersion: tuned.openshift.io/v1
kind: Tuned
metadata:
  name: cp4d-wkc-ipc
  namespace: openshift-cluster-node-tuning-operator
spec:
  profile:
  - name: cp4d-wkc-ipc
    data: |
      [main]
      summary=Tune IPC Kernel parameters on OpenShift Worker Nodes running WKC Pods
      [sysctl]
      kernel.shmall = 33554432
      kernel.shmmax = 68719476736
      kernel.shmmni = 16384
      kernel.sem = 250 1024000 100 16384
      kernel.msgmax = 65536
      kernel.msgmnb = 65536
      kernel.msgmni = 32768
      vm.max_map_count = 262144
  recommend:
  - match:
    - label: node-role.kubernetes.io/worker
    priority: 10
    profile: cp4d-wkc-ipc
```

Run below commands to do the changes

```
oc project kube-system
oc create -f setkernelparameters.yaml
```

4.	Change NFS mount settings
If you are using IBM Cloud File Storage for PVC creation, we need to make sure pvcs are mounted with root permissions. 

a.	Create a service account called norootsquash by running the following command:

```
oc create -f - << EOF
apiVersion: v1
kind: ServiceAccount
metadata:
  name: norootsquash
  namespace: kube-system
EOF
```

b.	Give the service account privileged security context constraints (SCC) by running the following command:

``` 
oc adm policy add-scc-to-user privileged system:serviceaccount:kube-system:norootsquash
```

c.	Create the daemonset by running the following command:

```
oc create -f - << EOF
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: norootsquash
  namespace: kube-system
  labels:
    tier: management
    app: norootsquash
spec:
  selector:
    matchLabels:
      name: norootsquash
  template:
    metadata:
      labels:
        name: norootsquash
    spec:
      serviceAccountName: norootsquash
      initContainers:
        - resources:
            requests:
              cpu: 0.1
          securityContext:
            privileged: true
          image: alpine:3.6
          name: unrootsquash
          command: ["chroot", "/host", "sh", "-c"]
          args:
            - >
              grep "^Domain = slnfsv4.com" /etc/idmapd.conf;
              if [ "\$?" -ne "0" ] ; then
                sed -i 's/.*Domain =.*/Domain = slnfsv4.com/g' /etc/idmapd.conf;
                nfsidmap -c;
                rpc.idmapd
              fi;
          volumeMounts:
            - name: host
              mountPath: /host
      containers:
        - resources:
            requests:
              cpu: 0.1
          image: alpine:3.6
          name: sleep
          command: ["/bin/sh", "-c"]
          args:
            - >
              while true; do
                sleep 100000;
              done
      volumes:
        - hostPath:
            path: /
            type: Directory
          name: host
EOF
```

### Setting Portworx Storage

Watson AI services (Watson Assistant, Watson Discovery, Watson Knowledge Studio, Watson Speech to Text and Watson text to Speech) install is currently supported only with Enterprise Portworx storage. Follow the steps mentioned below to set that up for ROKS. Make sure you are logged in to IBM Cloud and Openshift using CLI (ibmcloud and oc)
1.	Attach Block Storage to worker nodes (https://cloud.ibm.com/docs/containers?topic=containers-utilities#block_storage_attacher)
a.	Install helm on your local system from where you are running the commands. (https://github.com/helm/helm/releases)
b.	oc project kube-system	
c.	oc get serviceaccount -n kube-system | grep tiller 
It should return 0 results
d.	oc create serviceaccount tiller -n kube-system
e.	oc create clusterrolebinding tiller --clusterrole=cluster-admin --serviceaccount=kube-system:tiller -n kube-system
f.	oc get serviceaccount -n kube-system tiller
g.	helm init --service-account tiller
h.	oc get pods -n kube-system -l app=helm
i.	helm repo add iks-charts https://icr.io/helm/iks-charts
j.	helm repo add ibm-charts https://raw.githubusercontent.com/IBM/charts/master/repo/stable
k.	helm repo add ibm-community https://raw.githubusercontent.com/IBM/charts/master/repo/community
l.	helm repo add entitled https://raw.githubusercontent.com/IBM/charts/master/repo/entitled
m.	helm repo update
n.	helm install iks-charts/ibm-block-storage-attacher --name block-attacher
o.	oc get pod -n kube-system -o wide | grep attacher
p.	oc get storageclasses | grep attacher
q.	mkdir cp4d
r.	cd cp4d
s.	git clone https://github.com/IBM/ibmcloud-storage-utilities.git
t.	cd ibmcloud-storage-utilities/block-storage-provisioner
u.	vi yamlgen.yaml (provide the storage as you would need for your application, clustername and size of the block storage. Min 500 GB is required for Watson Assistant)
Provide the storage details i.e your Openshift Cluster name and region where it is located.
 

v.	Create Classic Infrastructure Key
a.	On IBM Cloud Console, from menu bar select Manage -> Access
b.	Select API keys tab and from drop down select Classic Infrastructure API keys.
c.	If one is already listed, click Actions menu (3 dots) > Details
d.	Copy API username and API key

 

w.	export SL_USERNAME=<infrastructure username obtained in above step>
x.	export SL_API_KEY=<infrastructure API key obtained in above step>
y.	Edit Dockerfile and update first line to “FROM ubuntu:18.04”
z.	Edit px_iks_utils.py (only if you have virtual server nodes as well as bare metal nodes, this is to avoid attaching block storage on virtual server nodes). Add below line on line number 83

if re.search('m[a-z]3c', w['machineType']):

It should like this 

 

Add “import re” on the top below existing import statements.
aa.	docker build -t mkpvyaml .
bb.	docker run --rm -v `pwd`:/data -v ~/.bluemix:/config -e SL_API_KEY=$SL_API_KEY -e SL_USERNAME=$SL_USERNAME mkpvyaml
cc.	oc apply -f pv-<cluster-name>.yaml
dd.	oc describe pv <pvname created in above step>  
(check for annotation ibm.io/attachstatus: attached)
ee.	Cordon nodes which are not bare metal server with below command. Execute below command for each non bare metal node.
oc adm cordon <node-name>

 

2.	To use internal portworx key-value database instead of etcd service, copy the imagepull secret from default to kube-system namespace.
a.	oc get secrets -n default | grep icr
b.	oc get secret -n default all-icr-io -o yaml | sed 's/default/kube-system/g' | oc -n kube-system create -f -
c.	oc patch -n kube-system serviceaccount/default --type='json' -p='[{"op":"add","path":"/imagePullSecrets/-","value":{"name”:”all-icr-io"}}]'

3.	From IBM Cloud Catalog, provision “Portworx Enterprise” service. Select same region as your Openshift Cluster. Select Enterprise plan from Pricing Plan. In IBM Cloud API Key, mention same key which was used to create block storage in above steps.  Select “Portworx KVDB” from Portworx metadata key-value store dropdown.

 

4.	Check if portworx pods are created and up successfully.
oc get pods -n kube-system | grep 'portworx\|stork'

5.	Login to one of the portworx pods and list the status of your Portworx cluster
PX_POD=$(oc get pods -l name=portworx -n kube-system -o jsonpath='{.items[0].metadata.name}')
       oc exec $PX_POD -n kube-system -- /opt/pwx/bin/pxctl status

Non-bare metal server worker nodes will be listed with No StorageNode.
 

